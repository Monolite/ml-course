{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto de Clasificación\n",
    "Para este proyecto trabajarán con el dataset\n",
    "[Heart Failure Prediction - Clinical Records](https://www.kaggle.com/datasets/aadarshvelu/heart-failure-prediction-clinical-records).\n",
    "Toda la información sobre el dataset la pueden encontrar en el link. Aprender a\n",
    "leer la información y entender cómo está construido un dataset es un *skill* muy\n",
    "importante, que deben desarrollar.\n",
    "\n",
    "Por otro lado, recuerden que Kaggle tiene una pestaña `Code`, donde pueden\n",
    "inspeccionar código de otras personas; siéntanse libres de hacerlo, ese es otro\n",
    "skill importante y es la forma en la que la mayoría de la gente en el campo\n",
    "aprende sobre nuevos modelos y se mantiene actualizada.\n",
    "\n",
    "Su proyecto deberá incluir:\n",
    "- Descarga e importación del Dataset\n",
    "- EDA: justificar por qué decidieron utilizar sus métodos de visualización,\n",
    "además de proporcionar alguna breve conclusión que obtengan a partir de su\n",
    "análisis de los datos\n",
    "- Metodos de validación: Hold-out y k-fold\n",
    "- Preproceso: justificar las operaciones realizadas\n",
    "- Entrenamiento de modelos:\n",
    "    - [kNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "    - [Regresión Logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "    - [Árboles de Decisión](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "    - [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "    - [Support Vector Machines](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). **Recurso:** [Support Vector Machines](https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-complete-guide-for-beginners/)\n",
    "    - Deberán trabajar con al menos dos modelos de los vistos en clase; el uso de\n",
    "    SVM es **obligatorio**, investigar sobre un método nuevo y animarse a\n",
    "    utilizar las implementaciones es, quizás, el *skill* más preciado que puedan\n",
    "    desarrollar.\n",
    "- Prueba y Desempeño del modelo\n",
    "- Conclusiones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports y variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "SEED = 73\n",
    "np.random.seed(SEED)\n",
    "\n",
    "file_path = 'heart_failure_clinical_records_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data as array\n",
    "ds_arr = np.loadtxt(file_path, delimiter=',', skiprows=1)\n",
    "\n",
    "# import data as pandas dataframe  \n",
    "ds_df = pd.read_csv(file_path)\n",
    "\n",
    "ds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "- ¿Mi banco de datos es balanceado?, ¿Cómo puedo saberlo?\n",
    "- ¿Qué otras visualizaciones puedo realizar para analizar mis datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ds_df.keys()\n",
    "\n",
    "ds_desc = ds_df.describe().T\n",
    "# ds_desc.insert(1, 'data_type', None)\n",
    "# ds_desc.insert(1, 'null_values_count', None)\n",
    "ds_desc.insert(1, 'values_type', None)\n",
    "ds_desc.insert(2, 'unique_val_cnt', None)\n",
    "ds_desc.insert(3, 'unique_values', None)\n",
    "\n",
    "\n",
    "for column in columns:\n",
    "    col_unique_data = ds_df[column].unique()\n",
    "    col_unique_data.sort()\n",
    "    col_type = 'continuous' if col_unique_data.size > 10  else 'discrete'\n",
    "\n",
    "    ds_desc.at[column, 'values_type'] = col_type\n",
    "    ds_desc.at[column, 'unique_val_cnt'] = col_unique_data.size\n",
    "    ds_desc.at[column, 'unique_values'] = col_unique_data\n",
    "\n",
    "ds_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ds_df['age'].unique()\n",
    "ages.sort()\n",
    "\n",
    "# print(ds_df['age'])\n",
    "\n",
    "ages_dict = dict()\n",
    "\n",
    "for age in ages:\n",
    "    ages_dict[age] = np.sum(ds_df['age'] == age)\n",
    "\n",
    "# print(ages_dict)\n",
    "\n",
    "# print(np.floor(ds_df['age'] / 10) * 10)\n",
    "\n",
    "# agesr_dict = dict()\n",
    "# agesr = np.floor(ds_df['age'] / 10) * 10\n",
    "# ages = agesr.unique()\n",
    "# ages.sort()\n",
    "\n",
    "# # print(agesr)\n",
    "\n",
    "# for age in agesr:\n",
    "#     agesr_dict[age] = np.sum(agesr == age)\n",
    "\n",
    "# print(agesr_dict)\n",
    "\n",
    "plt.bar(ages_dict.keys(), ages_dict.values())\n",
    "plt.show()\n",
    "\n",
    "# plt.bar(agesr_dict.keys(), agesr_dict.values(), width=8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación\n",
    "Utilizar Hold-out y k-fold. En caso de que el dataset sea desbalanceado, debemos\n",
    "de asegurar, en la medida de lo posible, que nuestras particiones respetarán la\n",
    "distribución de nuestros datos, el término `stratified` en `sklearn` hace\n",
    "referencia a este proceso.\n",
    "\n",
    "- [hold-out](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Si el dataset es desbalanceado, deberán utilizar el\n",
    "parámetro `stratify`.\n",
    "- [k-fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "- [Stratified k-fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)\n",
    "\n",
    "**Nota**: Recuerda que hold-out se ejecuta una sola vez, mientras que kfold se\n",
    "ejecuta k número de veces (requieres un ciclo `for` para ello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproceso\n",
    "- ¿Qué transformaciones debería hacer a mis datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo\n",
    "Utilizar al menos dos algoritmos de clase, además del clasificador de Máquinas\n",
    "de Soporte Vectorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba y desempeño del modelo\n",
    "Para problemas balanceados, ya vimos como se prueba y se mide el desempeño del\n",
    "modelo para ambos métodos de validación. Aunque `accuracy` es la métrica\n",
    "predilecta, nada impide, si así lo desean, que calculen alguna otra métrica que\n",
    "surja a partir de la matriz de confusión.\n",
    "\n",
    "En el caso de datasets desbalanceados, lo primero que deben de recordar es que\n",
    "`accuracy` **no es una métrica válida**, por lo que debemos recurrir a alguna\n",
    "otra métrica y a nuestra `matriz de confusión`. Para el caso de `hold-out`,\n",
    "basta con calcular el desempeño del modelo una vez ha sido entrenado y puesto a\n",
    "prueba. Sin embargo, en el caso de `k-fold`, no podemos calcular las métricas\n",
    "de desempeño del modelo en cada fold y luego promediar (cosa que hacemos cuando\n",
    "es balanceado y calculamos accuracy); debemos almacenar todas las predicciones y\n",
    "las ground truth de todos los folds (**conservando el orden en que fueron\n",
    "presentados al modelo**), y una vez que terminamos con los folds, debemos\n",
    "calcular la métrica de manera global.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A continuación se les proporciona un repaso de\n",
    "[la matriz de confusión y métricas de desempeño](https://www.analyticsvidhya.com/blog/2021/07/metrics-to-evaluate-your-classification-model-to-take-the-right-decisions/).\n",
    "\n",
    "Las métricas ya forman parte de `sklearn`:\n",
    "- [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "- [Balanced Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html)\n",
    "- [Recall (sensitivity)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
    "- [Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)\n",
    "- [F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
    "\n",
    "\n",
    "Veamos un caso de `k-fold` con datos desbalanceados y calculo de diferentes\n",
    "métricas. Solo crearemos un vector síntetico de ground truth, y en cada fold\n",
    "crearemos un vector de *predicciones* de manera aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, \\\n",
    "                            balanced_accuracy_score, precision_score\n",
    "                            \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits = 10\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=73)\n",
    "\n",
    "ones_ = np.ones((15,), dtype=int)\n",
    "zeros_ = np.zeros((85,), dtype=int)\n",
    "y = np.concatenate((ones_, zeros_))\n",
    "\n",
    "balanced_accuracy_avg = 0\n",
    "f1_avg = 0\n",
    "recall_avg = 0\n",
    "y_preds = []  # para guardar las predicciones de cada fold\n",
    "ys = []  # para guardar los valores reales de y de cada fold\n",
    "for train_index, test_index in kf.split(y, y):\n",
    "    \"\"\"\n",
    "    para el vector y_pred, solo hagamos de cuenta que son las predicciones de un\n",
    "    modelo ya entrenado.\n",
    "    \"\"\"\n",
    "    y_test = y[test_index]\n",
    "    y_pred = np.random.randint(0, 2, y_test.shape[0])\n",
    "\n",
    "    balanced_accuracy_avg += balanced_accuracy_score(y_test, y_pred)\n",
    "    f1_avg += f1_score(y_test, y_pred)\n",
    "    recall_avg += recall_score(y_test, y_pred)\n",
    "\n",
    "    y_preds += list(y_pred)\n",
    "    ys += list(y_test)\n",
    "\n",
    "print(10*'-' + ' Resultados ' + 10*'-')\n",
    "print(f\"Balanced accuracy avg: {balanced_accuracy_avg/n_splits}\")\n",
    "print(f\"Balanced accuracy global: {balanced_accuracy_score(ys, y_preds)}\")\n",
    "print()\n",
    "print(f\"F1 avg: {f1_avg/n_splits}\")\n",
    "print(f\"F1 global: {f1_score(ys, y_preds)}\")\n",
    "print()\n",
    "print(f\"Recall avg: {recall_avg/n_splits}\")\n",
    "print(f\"Recall global: {recall_score(ys, y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Confusión\n",
    "- [Matriz de confusión](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ys, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos guardar en variables los resultados de cada casi de la matriz\n",
    "tn, fp, fn, tp = confusion_matrix(ys, y_preds).ravel()\n",
    "\n",
    "# a partir de estos valores podemos calcular las métricas que queramos a mano\n",
    "# si asi lo deseamos\n",
    "\n",
    "# recall\n",
    "recall_own = tp / (tp + fn)\n",
    "recall_sk = recall_score(ys, y_preds)\n",
    "print(f\"Recall own: {recall_own}\")\n",
    "print(f\"Recall sk: {recall_sk}\")\n",
    "print(f\"Recall own == Recall sk: {recall_own == recall_sk}\")\n",
    "print()\n",
    "\n",
    "# precision\n",
    "precision_own = tp / (tp + fp)\n",
    "precision_sk = precision_score(ys, y_preds)\n",
    "print(f\"Precision own: {precision_own}\")\n",
    "print(f\"Precision sk: {precision_sk}\")\n",
    "print(f\"Precision own == Recall sk: {precision_own == precision_sk}\")\n",
    "print()\n",
    "\n",
    "# specificity no está programa, pero es un recall de la clase 0\n",
    "specificity_own = tn / (tn + fp)\n",
    "specificity_sk = recall_score(ys, y_preds, pos_label=0)\n",
    "print(f\"Specificity own: {specificity_own}\")\n",
    "print(f\"Specificity sk: {specificity_sk}\")\n",
    "print(f\"Specificity own == Recall sk: {specificity_own == specificity_sk}\")\n",
    "print()\n",
    "\n",
    "# balanced accuracy\n",
    "balanced_accuracy_own = (recall_own + specificity_own) / 2\n",
    "balanced_accuracy_sk = balanced_accuracy_score(ys, y_preds)\n",
    "print(f\"Recall own: {balanced_accuracy_own}\")\n",
    "print(f\"Recall sk: {balanced_accuracy_sk}\")\n",
    "print(f\"Recall own == Recall sk: {balanced_accuracy_own == balanced_accuracy_sk}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos visualizar mediante una gráfica de heatmap a nuestra matriz de\n",
    "confusión. La ventaja de esta gráfica es que nos mostrará cada casilla de\n",
    "nuestra matriz con un color que va de acuerdo con el valor que tiene dicha\n",
    "casilla:\n",
    "- entre más oscura sea la celda, mayor número de patrones caen en esa casilla\n",
    "- entre más clas sea, menos patrones encontramos ahí\n",
    "\n",
    "Una buena matriz de confusión es aquella para la cual su diagonal principal\n",
    "presenta colores oscuros y fuera de ella colores claros, mostrando así muchos\n",
    "aciertos (diagonal) y pocos errores (fuera de diagonal).\n",
    "\n",
    "Caso contrario, si llegamos a encontrar una casilla oscura fuera de la diagonal\n",
    "quiere decir que nuestro modelo está cometiendo muchos errores.\n",
    "\n",
    "Grafiquemos la matriz de confusión de nuestros datos sintéticos, y observemos\n",
    "que esta es una matriz no ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(ys, y_preds)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora visualicemos una matriz de confusión *optima* y una deficiente, para más\n",
    "clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.array([[48, 1, 1],\n",
    "               [1, 47, 2],\n",
    "               [2, 2, 46]])\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix Optima')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cm = np.array([[31, 14, 5],\n",
    "               [31, 5, 14],\n",
    "               [20, 20, 10]])\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix Optima')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ventaja de visualizar de esta manera la matriz de confusión es que podemos\n",
    "guiarnos únicamente por la escala de colores, sin tener que analizar a detalle\n",
    "los valores numéricos.\n",
    "\n",
    "Poder analizar la matriz de confusión mediante la escala de colores nos permite\n",
    "tener un *feeling* prácticamente instantáneo del desempeño del modelo; este\n",
    "*skill* es invaluable y, en definitiva, uno que les conviene desarrollar con la\n",
    "práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
